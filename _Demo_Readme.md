# MCP Demo
Check your local LLM settings and make sure that it is up and runnin.
## AnythingLLM Demo
Check the `anythingllm_mcp_servers.json` file and show users the contents of this file.
### - swapi-mcp-starter
- Check `swapi-mcp-starter` agent is ready in AnythingLLM settings.
- Check podman is running container
- First ask `who am I?` and see the LLM answer.
- Then ask the same question with the `@agent` command.
### - youtube-video-summarizer
- Before starting the presentation, run the command "npx @modelcontextprotocol/inspector node dist/index.js" in terminal.
- Check "youtube-video-summarizer" agent is ready in AnythingLLM settings.
- First ask `What are the key points from this video: https://www.youtube.com/watch?v=dQw4w9WgXcQ` and see the LLM answer.
- Then ask the same question with the "@agent" command.

## CodeAsistan (VsCode, Intellij)
### - Local Coding LMM (Intellij)
- Configure `DevoxxGenie` for local LLM.
- `swapi-mcp-starter`
  - Check podman is running container
  - First ask `who am I?` and see the LLM answer.
  - Then ask the same question with the `@agent` command.
- `Github MCP` server
- `Jira MCP` server
- `Postgresql MCP` Server

### - (Optional) Github Copilot (VS code)
 - Show MCP settings
 - `Github MCP` server

### - (Optional) Windsurf Copilot (Vs code)
 - Show MCP settings
 - `Github MCP` server
 
